{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Confusion Matrix Exercise.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPoef2NN+rK6qrIyMiEG3m7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahirag/Machine-Learning/blob/main/Confusion_Matrix_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQsgZr_A1LMx",
        "outputId": "8934fd2e-9341-45d6-f67a-9f146c4752d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syLLt65c8piH"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBcqYDGh8eqE"
      },
      "source": [
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "ayS31GEN2gIZ",
        "outputId": "c64bff92-d419-4906-c2d2-bf248f522574"
      },
      "source": [
        "filename = '/content/drive/My Drive/cancer (1).csv'\n",
        "df = pd.read_csv(filename)\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0      842302         M  ...          0.4601                  0.11890\n",
              "1      842517         M  ...          0.2750                  0.08902\n",
              "2    84300903         M  ...          0.3613                  0.08758\n",
              "3    84348301         M  ...          0.6638                  0.17300\n",
              "4    84358402         M  ...          0.2364                  0.07678\n",
              "..        ...       ...  ...             ...                      ...\n",
              "564    926424         M  ...          0.2060                  0.07115\n",
              "565    926682         M  ...          0.2572                  0.06637\n",
              "566    926954         M  ...          0.2218                  0.07820\n",
              "567    927241         M  ...          0.4087                  0.12400\n",
              "568     92751         B  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 32 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWL5yT79iM2"
      },
      "source": [
        "1) Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpYx_2m94Utg",
        "outputId": "c2de7440-1371-4e48-e741-ac75b901f8b7"
      },
      "source": [
        "# by using normalize = True with value_counts, our output is the percentage of each class (written as a decimal)\n",
        "df['diagnosis'].value_counts(normalize = True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    0.627417\n",
              "M    0.372583\n",
              "Name: diagnosis, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXrM5jX69nEj"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTn9WI2Q4cnn"
      },
      "source": [
        "df['diagnosis'] = df['diagnosis'].replace({'B': 0, 'M': 1})"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi0O1pgY4gEi"
      },
      "source": [
        "y = df['diagnosis']\n",
        "X = df.drop(columns = 'diagnosis')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRpAyqK44kj0"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4hHpoKc4mbt"
      },
      "source": [
        "dec_tree = DecisionTreeClassifier(random_state = 42)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH25id-_4vUp",
        "outputId": "2fe22147-b84f-4f1c-da32-2bac2374fe55"
      },
      "source": [
        "# Looking at some hyperparameters that seem tunable\n",
        "dec_tree"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=42, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI_xm1Vk4yx8",
        "outputId": "51eb7817-d8fb-4907-c1de-f0a3d4ccb04b"
      },
      "source": [
        "dec_tree.fit(X_train, y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=42, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYXSvOEy41Qq",
        "outputId": "8556a28e-f9d0-4c24-fa63-0625f8dfb21d"
      },
      "source": [
        "dec_tree.predict(X_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXQG-DOMEiOW"
      },
      "source": [
        "1)What was the accuracy of the model?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCdbdV5I5-oB",
        "outputId": "9b16c72c-f0ce-4f16-e486-a6a545b2a0da"
      },
      "source": [
        "# calculate classification accuracy\n",
        "train_score = dec_tree.score(X_train, y_train)\n",
        "test_score = dec_tree.score(X_test, y_test)\n",
        "print(train_score)\n",
        "print(test_score)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.951048951048951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "LygUogruD82e",
        "outputId": "dda10462-0e14-4465-aa28-9fb33324854c"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "plot_confusion_matrix(dec_tree, X_test, y_test, cmap = 'Blues');"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEviRbMPEn9e"
      },
      "source": [
        "\n",
        "2) Which condition (Malignant or Benign) is considered the positive class in this data set?\n",
        "\n",
        "Ans: Malignant\n",
        "\n",
        "\n",
        "3) How many false positives were there?\n",
        "\n",
        "Ans: 5\n",
        "\n",
        "4) How many false negatives were there?\n",
        "\n",
        "Ans: 2\n",
        "\n",
        "5) For the breast cancer data set, which do you think is more problematic: false positives or false negatives? Explain.  \n",
        "\n",
        "Ans: False negatives because that means that the cancer was not detected in the patient.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}